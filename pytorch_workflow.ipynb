{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJIgyCnxVG96gjJmOgWfN/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobotMa/PyTorch/blob/master/pytorch_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6QPtJJZqwSS",
        "outputId": "25148b40-18a6-4626-f4d5-da694b045ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.__version__\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Regression Formula"
      ],
      "metadata": {
        "id": "SDYSQFqot2I3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create *known* parameters\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Create data\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
        "y = weight * X + bias\n",
        "\n",
        "X[:10], y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQRK4p1FrQZy",
        "outputId": "d7d4d272-8be3-41ba-ef0d-c61cec089064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0000],\n",
              "         [0.0200],\n",
              "         [0.0400],\n",
              "         [0.0600],\n",
              "         [0.0800],\n",
              "         [0.1000],\n",
              "         [0.1200],\n",
              "         [0.1400],\n",
              "         [0.1600],\n",
              "         [0.1800]]),\n",
              " tensor([[0.3000],\n",
              "         [0.3140],\n",
              "         [0.3280],\n",
              "         [0.3420],\n",
              "         [0.3560],\n",
              "         [0.3700],\n",
              "         [0.3840],\n",
              "         [0.3980],\n",
              "         [0.4120],\n",
              "         [0.4260]]))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "id": "YfrvlkmDuoKh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c255f672-3422-48ff-bd64-20eeb91cff86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([40, 1]),\n",
              " torch.Size([40, 1]),\n",
              " torch.Size([10, 1]),\n",
              " torch.Size([10, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create linear regression model class\n",
        "class LinearRegressionModel(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    # self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "    self.linear_layer = nn.Linear(in_features=1, out_features=1)\n",
        "\n",
        "  def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "    return self.linear_layer(X)"
      ],
      "metadata": {
        "id": "M68wiG5vwnIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### PyTorch model building essentials\n",
        "torch.manual_seed( 42 )\n",
        "\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1oLIpm13iwx",
        "outputId": "871c3940-d3e2-485b-d9b2-886a4fda40f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_layer.weight', tensor([[0.7645]])),\n",
              "             ('linear_layer.bias', tensor([0.8300]))])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()\n",
        "\n",
        "next(model_0.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGTpT0Lk-yMp",
        "outputId": "60be18da-1500-4c29-f246-299e8c7ad5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making prediction using `torch.inference_mode()`"
      ],
      "metadata": {
        "id": "p7YuHhmKVQXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a loss\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Set up an optimizer\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "RrwWLrrSZctP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "### Building a training loop (and a testing loop) in PyTorch\n",
        "epochs = 300\n",
        "\n",
        "# Track different values\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model_0.train()\n",
        "\n",
        "  y_pred = model_0(X_train)\n",
        "\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  model_0.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    test_pred = model_0(X_test)\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "\n",
        "    print(loss)\n",
        "    print(model_0.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iv2iiOAxbeEw",
        "outputId": "6c7f12b8-a3c6-4cae-9b01-fb3dacbd3888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5552, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7606]])), ('linear_layer.bias', tensor([0.8200]))])\n",
            "tensor(0.4400, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.7216]])), ('linear_layer.bias', tensor([0.7200]))])\n",
            "tensor(0.3248, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6826]])), ('linear_layer.bias', tensor([0.6200]))])\n",
            "tensor(0.2095, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6436]])), ('linear_layer.bias', tensor([0.5200]))])\n",
            "tensor(0.0943, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6046]])), ('linear_layer.bias', tensor([0.4200]))])\n",
            "tensor(0.0239, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.5872]])), ('linear_layer.bias', tensor([0.3525]))])\n",
            "tensor(0.0200, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6025]])), ('linear_layer.bias', tensor([0.3410]))])\n",
            "tensor(0.0165, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6196]])), ('linear_layer.bias', tensor([0.3340]))])\n",
            "tensor(0.0131, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6366]])), ('linear_layer.bias', tensor([0.3265]))])\n",
            "tensor(0.0097, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6537]])), ('linear_layer.bias', tensor([0.3195]))])\n",
            "tensor(0.0062, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6707]])), ('linear_layer.bias', tensor([0.3120]))])\n",
            "tensor(0.0028, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6878]])), ('linear_layer.bias', tensor([0.3050]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n",
            "tensor(0.0013, grad_fn=<MeanBackward0>)\n",
            "OrderedDict([('linear_layer.weight', tensor([[0.6929]])), ('linear_layer.bias', tensor([0.2925]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions=y_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "k7ToDKkh7vYJ",
        "outputId": "21cabb1d-8f3e-4ef4-8fa3-1d2ddaddb6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plot_predictions' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ee0e1d63918e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_predictions' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values)), label=\"Train loss\")\n",
        "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "y-ykkPmyTt_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save a Model"
      ],
      "metadata": {
        "id": "LpwE0omLtUcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "MODEL_PATH = Path(\"models\")\n",
        "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"01_pytorch_workflow_model_0.pth\"\n",
        "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
        "\n",
        "print(f\"Saving model to {MODEL_SAVE_PATH}\")\n",
        "torch.save(obj=model_0.state_dict(), f=MODEL_SAVE_PATH)"
      ],
      "metadata": {
        "id": "Tz4yjd6TpY3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HcFEf5rX0a2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model_0 = LinearRegressionModel()\n",
        "\n",
        "print(loaded_model_0.state_dict())\n",
        "\n",
        "loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
        "\n",
        "print(loaded_model_0.state_dict())"
      ],
      "metadata": {
        "id": "ZOQKwY7nzxVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Putting it all together"
      ],
      "metadata": {
        "id": "8s6dN3Srfsue"
      }
    }
  ]
}